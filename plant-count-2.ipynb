{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12097687,"sourceType":"datasetVersion","datasetId":7615976},{"sourceId":12238609,"sourceType":"datasetVersion","datasetId":7711235},{"sourceId":12238681,"sourceType":"datasetVersion","datasetId":7711287},{"sourceId":12308991,"sourceType":"datasetVersion","datasetId":7758516},{"sourceId":12317200,"sourceType":"datasetVersion","datasetId":7763803},{"sourceId":12317400,"sourceType":"datasetVersion","datasetId":7763952},{"sourceId":12319290,"sourceType":"datasetVersion","datasetId":7765149},{"sourceId":12319399,"sourceType":"datasetVersion","datasetId":7765221},{"sourceId":12364747,"sourceType":"datasetVersion","datasetId":7795960},{"sourceId":12378874,"sourceType":"datasetVersion","datasetId":7805407}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics roboflow opencv-python matplotlib pillow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\nfrom roboflow import Roboflow\nimport numpy as np\nfrom PIL import Image\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\n\ndef download_dataset():\n    from roboflow import Roboflow\n    rf = Roboflow(api_key=\"QHr9qKdWagsf1TvMIUq1\")\n    project = rf.workspace(\"sanjrani\").project(\"potato-plant-30d\")\n    version = project.version(9)\n    dataset = version.download(\"yolov11\")\n    return dataset.location\n\n# Uncomment to download dataset\ndataset_path = download_dataset()\nprint(f\"Dataset downloaded to: {dataset_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 2.5: Check GPU first (run this before training)\ndef check_gpu_setup():\n    import torch\n    if torch.cuda.is_available():\n        print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n        print(f\"‚úÖ Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n        return True\n    else:\n        print(\"‚ùå GPU not available - check Kaggle accelerator settings\")\n        return False\n\ncheck_gpu_setup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(dataset_path):\n    import torch\n    \n    # Explicitly check and set device\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"üöÄ Training on: {device}\")\n    \n    # Load model\n    model = YOLO('yolo11m-seg.pt')  # Medium model for better accuracy\n    \n    # Train with explicit GPU settings\n    results = model.train(\n        data=f\"{dataset_path}/data.yaml\",\n        epochs=10,  # Your original setting\n        imgsz=640,\n        batch=16,  # Increased for GPU\n        device=device,  # Explicitly set device\n        workers=2,  # Good for Kaggle\n        name='potato_counter'\n    )\n    \n    return \"runs/segment/potato_counter3/weights/best.pt\"\n\n# Your training call\nmodel_path = train_model(\"/kaggle/working/potato-plant-30D-9\")\nprint(f\"Model trained and saved to: {model_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load your trained model (replace with your model path)\nMODEL_PATH = '/kaggle/input/orthofiles/best.pt'  # Update this path\nmodel = YOLO(MODEL_PATH)\nprint(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T11:41:36.680980Z","iopub.execute_input":"2025-06-29T11:41:36.681252Z","iopub.status.idle":"2025-06-29T11:41:36.768387Z","shell.execute_reply.started":"2025-06-29T11:41:36.681231Z","shell.execute_reply":"2025-06-29T11:41:36.767669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt \ndef count_potato_plants(image_path, confidence=0.5, show_image=True):\n    \"\"\"\n    Count potato plants in an image\n    \n    Args:\n        image_path: Path to the image\n        confidence: Detection confidence threshold (0.0 - 1.0)\n        show_image: Whether to display the annotated image\n    \n    Returns:\n        int: Number of plants detected\n    \"\"\"\n    \n    # Read image\n    image = cv2.imread(IMAGE_PATH)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # Run inference\n    results = model(image, conf=confidence)\n    \n    # Count detections\n    plant_count = 0\n    if results[0].boxes is not None:\n        plant_count = len(results[0].boxes)\n    \n    # Show annotated image\n    if show_image:\n        # Get annotated image from YOLO\n        annotated_image = results[0].plot()\n        \n        # Display using matplotlib\n        plt.figure(figsize=(10, 5))\n        plt.imshow(annotated_image)\n        plt.title(f'Detected {plant_count} Potato Plants', fontsize=16)\n        plt.axis('off')\n        plt.show()\n    \n    print(f\"üå± Found {plant_count} potato plants!\")\n    return plant_count\nIMAGE_PATH = \"/kaggle/input/tif-files/DJI_20250624143217_0002_D.tif\"\n\n# Count plants with default settings\nplant_count = count_potato_plants(IMAGE_PATH, confidence=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T11:41:39.981369Z","iopub.execute_input":"2025-06-29T11:41:39.981874Z","iopub.status.idle":"2025-06-29T11:41:42.411678Z","shell.execute_reply.started":"2025-06-29T11:41:39.981850Z","shell.execute_reply":"2025-06-29T11:41:42.411034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt \ndef count_potato_plants(image_path, confidence=0.5, show_image=True):\n    \"\"\"\n    Count potato plants in an image\n    \n    Args:\n        image_path: Path to the image\n        confidence: Detection confidence threshold (0.0 - 1.0)\n        show_image: Whether to display the annotated image\n    \n    Returns:\n        int: Number of plants detected\n    \"\"\"\n    \n    # Read image\n    image = cv2.imread(IMAGE_PATH)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # Run inference\n    results = model(image, conf=confidence)\n    \n    # Count detections\n    plant_count = 0\n    if results[0].boxes is not None:\n        plant_count = len(results[0].boxes)\n    \n    # Show annotated image\n    if show_image:\n        # Get annotated image from YOLO\n        annotated_image = results[0].plot()\n        \n        # Display using matplotlib\n        plt.figure(figsize=(15, 10))\n        plt.imshow(annotated_image)\n        plt.title(f'Detected {plant_count} Potato Plants', fontsize=16)\n        plt.axis('off')\n        plt.show()\n    \n    print(f\"üå± Found {plant_count} potato plants!\")\n    return plant_count\nIMAGE_PATH = \"/kaggle/input/sampling-dataset/s3 blue hoop 4m.jpg\"\n\n# Count plants with default settings\nplant_count = count_potato_plants(IMAGE_PATH, confidence=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:45:25.611432Z","iopub.execute_input":"2025-06-21T14:45:25.611726Z","iopub.status.idle":"2025-06-21T14:45:28.665194Z","shell.execute_reply.started":"2025-06-21T14:45:25.611705Z","shell.execute_reply":"2025-06-21T14:45:28.664126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install ultralytics sahi opencv-python-headless\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:21:10.436056Z","iopub.execute_input":"2025-07-04T15:21:10.436338Z","iopub.status.idle":"2025-07-04T15:22:32.714144Z","shell.execute_reply.started":"2025-07-04T15:21:10.436290Z","shell.execute_reply":"2025-07-04T15:22:32.713309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n# Increase pixel limit before any OpenCV import\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(10**13)  # 1 trillion pixels\n\nfrom PIL import Image\nimport numpy as np\nimport torch\nfrom sahi import AutoDetectionModel\n\nfrom sahi.predict import get_sliced_prediction\nimport cv2\n\n# Load image with PIL (handles large files better)\nimage_path = '/kaggle/input/sampling-dataset/s3 rainbow hoop 3m.jpg'\npil_image = Image.open(image_path)\northo_image = np.array(pil_image)  # Shape: (height, width, 3)\n\n# Convert RGB to BGR for OpenCV compatibility\northo_image = cv2.cvtColor(ortho_image, cv2.COLOR_RGB2BGR)\n\n# Initialize model (corrected parameters)\ndetection_model = AutoDetectionModel.from_pretrained(\n    model_type='yolov8',\n    model_path='/kaggle/input/potatot30d-weights/potato t30D.pt',\n    confidence_threshold=0.2,\n    device='cuda:0' if torch.cuda.is_available() else 'cpu',\n    category_mapping={'0': 'potato T30 D'}  # Replace with your class mapping\n)\n\n# Perform tiled inference\nresult = get_sliced_prediction(\n    ortho_image,  # Use the numpy array directly\n    detection_model,\n    slice_height=3000,\n    slice_width=3000,\n    overlap_height_ratio=0.2,\n    overlap_width_ratio=0.2\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:26:18.839933Z","iopub.execute_input":"2025-07-04T15:26:18.840205Z","iopub.status.idle":"2025-07-04T15:26:24.733353Z","shell.execute_reply.started":"2025-07-04T15:26:18.840187Z","shell.execute_reply":"2025-07-04T15:26:24.732773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result.export_visuals('output_dir2/')  # Saves mask overlays\n# result.to_coco('annotations.json')     # COCO format for GIS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:26:24.991493Z","iopub.execute_input":"2025-07-04T15:26:24.991806Z","iopub.status.idle":"2025-07-04T15:26:41.204460Z","shell.execute_reply.started":"2025-07-04T15:26:24.991784Z","shell.execute_reply":"2025-07-04T15:26:41.203905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\n# Display composite visualization\ndisplay(Image(filename='/kaggle/working/output_dir2/prediction_visual.png'))\n\n# Display sample mask\n# display(Image(filename='output/instance_0_mask.png'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T15:26:41.205334Z","iopub.execute_input":"2025-07-04T15:26:41.205514Z","iopub.status.idle":"2025-07-04T15:26:42.006413Z","shell.execute_reply.started":"2025-07-04T15:26:41.205500Z","shell.execute_reply":"2025-07-04T15:26:42.005637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n# Set environment variables FIRST\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(10**13)  # 1 trillion pixels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T12:06:15.829143Z","iopub.execute_input":"2025-06-29T12:06:15.829393Z","iopub.status.idle":"2025-06-29T12:06:15.833475Z","shell.execute_reply.started":"2025-06-29T12:06:15.829376Z","shell.execute_reply":"2025-06-29T12:06:15.832792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install missing dependencies\n!pip install -q torch sahi opencv-python-headless matplotlib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:26:12.515789Z","iopub.execute_input":"2025-07-05T08:26:12.516021Z","iopub.status.idle":"2025-07-05T08:27:30.184909Z","shell.execute_reply.started":"2025-07-05T08:26:12.515997Z","shell.execute_reply":"2025-07-05T08:27:30.183996Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.0/112.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:29:21.808696Z","iopub.execute_input":"2025-07-05T08:29:21.809245Z","iopub.status.idle":"2025-07-05T08:29:25.997513Z","shell.execute_reply.started":"2025-07-05T08:29:21.809214Z","shell.execute_reply":"2025-07-05T08:29:25.996594Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.162-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.162-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.162 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n# Set environment variables FIRST\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(10**13)  # 1 trillion pixels\n\n\nfrom PIL import Image\nimport numpy as np\nimport torch\nfrom sahi import AutoDetectionModel\nfrom sahi.predict import get_sliced_prediction\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Load and preprocess image\nimage_path = '/kaggle/input/lomond-files-t45d/DJI_20250625044135_0012_D.JPG'\npil_image = Image.open(image_path)\northo_image = np.array(pil_image)\northo_image = cv2.cvtColor(ortho_image, cv2.COLOR_RGB2BGR)\n\n# Initialize model\ndetection_model = AutoDetectionModel.from_pretrained(\n    model_type='yolov8',\n    model_path='/kaggle/input/potatot30d-weights/potato t30D.pt',\n    confidence_threshold=0.1,\n    device='cuda:0' if torch.cuda.is_available() else 'cpu',\n    category_mapping={'0': 'potato'}\n)\n\n# Perform inference\nresult = get_sliced_prediction(\n    ortho_image,\n    detection_model,\n    slice_height=3000,\n    slice_width=3000,\n    overlap_height_ratio=0.2,\n    overlap_width_ratio=0.2\n)\n\n# Count plants\nplant_count = len(result.object_prediction_list)\nprint(f\"Detected plants: {plant_count}\")\n\nresult.export_visuals('output_dir2/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T08:29:37.498745Z","iopub.execute_input":"2025-07-05T08:29:37.499515Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nPerforming prediction on 4 slices.\nDetected plants: 85\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\n# Display composite visualization\ndisplay(Image(filename='/kaggle/working/output_dir2/prediction_visual.png'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T18:25:37.251899Z","iopub.execute_input":"2025-07-03T18:25:37.252623Z","iopub.status.idle":"2025-07-03T18:25:37.986213Z","shell.execute_reply.started":"2025-07-03T18:25:37.252596Z","shell.execute_reply":"2025-07-03T18:25:37.984692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_potato_plants(image_path, confidence, show_image=False):\n    import os\n    import cv2\n    print(f\"\\nüî• Processing NEW image: {image_path}\")\n    img = cv2.imread(image_path)\n    print(f\"Image shape: {img.shape} | Mean pixel value: {img.mean():.1f}\")\n    \n\n    \n    results = {}\n    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n    \n    # Get all image files (with absolute paths)\n    image_files = []\n    for ext in image_extensions:\n        image_files.extend([\n            os.path.join(image_folder, f) \n            for f in os.listdir(image_folder) \n            if f.lower().endswith(ext)\n        ])\n    \n    print(f\"Processing {len(image_files)} images...\")\n    \n    total_plants = 0\n    for i, image_path in enumerate(image_files, 1):\n        try:\n            # Verify the image is readable and unique\n            img = cv2.imread(image_path)\n            if img is None:\n                print(f\"‚ö†Ô∏è Could not read: {image_path}\")\n                results[os.path.basename(image_path)] = 0\n                continue\n                \n            # DEBUG: Print image hash to verify uniqueness\n            img_hash = hash(img.tobytes())\n            print(f\"Processing {i}/{len(image_files)}: {os.path.basename(image_path)} [Hash: {img_hash}]\")\n            \n            # Count plants\n            count = count_potato_plants(image_path, confidence, show_image=False)\n            \n            results[os.path.basename(image_path)] = count\n            total_plants += count\n            \n            # Force cleanup\n            del img\n            \n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error processing {os.path.basename(image_path)}: {str(e)}\")\n            results[os.path.basename(image_path)] = 0\n    \n    print(f\"\\nüìä SUMMARY:\")\n    print(f\"Total Images: {len(image_files)}\")\n    print(f\"Total Plants: {total_plants}\")\n    print(f\"Average Plants per Image: {total_plants/len(image_files):.1f}\")\n    \n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}